{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercício 7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SF72lgf_xDMC"
      },
      "source": [
        "### ***Model***  = MLPWithTensorFlowLowLevelAPI.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW6NgxE-t5uT"
      },
      "source": [
        "# Definindo a versão do tensorflow:\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26czP6JRtums"
      },
      "source": [
        "# Importando as bibliotecas necessárias:\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import graphviz as tfg              # Usar este código! \n",
        "from tensorboard import notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFmSwDjNuAML"
      },
      "source": [
        "# to make this notebook's output stable across runs\n",
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj411yRWutaC"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "n_inputs = 28*28 # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1hmzYOju6kh"
      },
      "source": [
        "Dispensa o '***neuron_layer***'\n",
        "\n",
        "```\n",
        "def neuron_layer(X, n_neurons, name, activation=None):\n",
        "    with tf.name_scope(name):\n",
        "        n_inputs = int(X.get_shape()[1])\n",
        "        stddev = 2 / np.sqrt(n_inputs)\n",
        "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
        "        W = tf.Variable(init, name=\"weights\")\n",
        "        b = tf.Variable(tf.zeros([n_neurons]), name=\"biases\")\n",
        "        z = tf.matmul(X, W) + b\n",
        "        if activation==\"relu\":\n",
        "            return tf.nn.relu(z)\n",
        "        else:\n",
        "            return z\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDSCG4Kwuu4n"
      },
      "source": [
        "# Importando as bibliotecas para usar o Dense():\n",
        "from keras.layers import Activation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9R-eJrWvNPe",
        "outputId": "fec464ff-825d-4e60-9ec6-4600fbfe61f8"
      },
      "source": [
        "# Configurando modo de compatibilidade com a V1.x\n",
        "tf.compat.v1.keras.layers.Dense"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.keras.layers.core.Dense"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPslIA36wRTz"
      },
      "source": [
        "Substituição da função ***neuron_layer***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LpiJSYQE4zx"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ3dPR-tweec"
      },
      "source": [
        "learning_rate = 0.01\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int64, shape=(None), name=\"y\")\n",
        "\n",
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\")\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                              activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
        "    y_proba = tf.nn.softmax(logits)\n",
        "    \n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "\n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "    \n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "    \n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65l-yUhoxrR6",
        "outputId": "7b084d4f-9064-48aa-93ff-5feb1cc41a1e"
      },
      "source": [
        "n_epochs = 20\n",
        "n_batches = 50\n",
        "n_epochs = 40\n",
        "batch_size = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.9 Validation accuracy: 0.9054\n",
            "1 Batch accuracy: 0.92 Validation accuracy: 0.9244\n",
            "2 Batch accuracy: 0.94 Validation accuracy: 0.9336\n",
            "3 Batch accuracy: 0.88 Validation accuracy: 0.9358\n",
            "4 Batch accuracy: 0.96 Validation accuracy: 0.9436\n",
            "5 Batch accuracy: 0.94 Validation accuracy: 0.948\n",
            "6 Batch accuracy: 1.0 Validation accuracy: 0.9542\n",
            "7 Batch accuracy: 0.94 Validation accuracy: 0.9556\n",
            "8 Batch accuracy: 0.94 Validation accuracy: 0.956\n",
            "9 Batch accuracy: 0.94 Validation accuracy: 0.9592\n",
            "10 Batch accuracy: 0.92 Validation accuracy: 0.961\n",
            "11 Batch accuracy: 1.0 Validation accuracy: 0.9628\n",
            "12 Batch accuracy: 0.98 Validation accuracy: 0.9622\n",
            "13 Batch accuracy: 0.98 Validation accuracy: 0.9648\n",
            "14 Batch accuracy: 1.0 Validation accuracy: 0.966\n",
            "15 Batch accuracy: 0.94 Validation accuracy: 0.9668\n",
            "16 Batch accuracy: 0.98 Validation accuracy: 0.9674\n",
            "17 Batch accuracy: 1.0 Validation accuracy: 0.9688\n",
            "18 Batch accuracy: 0.96 Validation accuracy: 0.97\n",
            "19 Batch accuracy: 0.96 Validation accuracy: 0.9694\n",
            "20 Batch accuracy: 1.0 Validation accuracy: 0.9696\n",
            "21 Batch accuracy: 1.0 Validation accuracy: 0.9694\n",
            "22 Batch accuracy: 0.96 Validation accuracy: 0.9702\n",
            "23 Batch accuracy: 0.98 Validation accuracy: 0.9712\n",
            "24 Batch accuracy: 0.98 Validation accuracy: 0.972\n",
            "25 Batch accuracy: 0.98 Validation accuracy: 0.972\n",
            "26 Batch accuracy: 0.92 Validation accuracy: 0.9722\n",
            "27 Batch accuracy: 1.0 Validation accuracy: 0.9732\n",
            "28 Batch accuracy: 0.94 Validation accuracy: 0.9726\n",
            "29 Batch accuracy: 0.98 Validation accuracy: 0.9736\n",
            "30 Batch accuracy: 1.0 Validation accuracy: 0.973\n",
            "31 Batch accuracy: 0.94 Validation accuracy: 0.9742\n",
            "32 Batch accuracy: 0.96 Validation accuracy: 0.9744\n",
            "33 Batch accuracy: 0.98 Validation accuracy: 0.9758\n",
            "34 Batch accuracy: 0.98 Validation accuracy: 0.9756\n",
            "35 Batch accuracy: 1.0 Validation accuracy: 0.9756\n",
            "36 Batch accuracy: 0.98 Validation accuracy: 0.9752\n",
            "37 Batch accuracy: 0.98 Validation accuracy: 0.9756\n",
            "38 Batch accuracy: 0.98 Validation accuracy: 0.9752\n",
            "39 Batch accuracy: 1.0 Validation accuracy: 0.977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGSRu4x2EylQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}