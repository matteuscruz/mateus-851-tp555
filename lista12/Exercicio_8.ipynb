{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercicio_8.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "baw-i8au_vG3"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2wt-jS5_3MR"
      },
      "source": [
        "# Importando as bibliotecas necess√°rias:\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXla3lmA_3o-"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "X_train = X_train.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "X_test = X_test.astype(np.float32).reshape(-1, 28*28) / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "X_valid, X_train = X_train[:5000], X_train[5000:]\n",
        "y_valid, y_train = y_train[:5000], y_train[5000:]"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYCWw__R_8j-"
      },
      "source": [
        "def reset_graph(seed=42):\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "def shuffle_batch(X, y, batch_size):\n",
        "    rnd_idx = np.random.permutation(len(X))\n",
        "    n_batches = len(X) // batch_size\n",
        "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
        "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
        "        yield X_batch, y_batch"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikdEASoC_9jV"
      },
      "source": [
        "n_inputs = 28*28  # MNIST\n",
        "n_hidden1 = 300\n",
        "n_hidden2 = 100\n",
        "n_outputs = 10\n",
        "learning_rate = 0.01"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FSYoQwi__cG"
      },
      "source": [
        "reset_graph()\n",
        "\n",
        "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
        "y = tf.placeholder(tf.int32, shape=(None), name=\"y\")"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EJBa7fNABOx",
        "outputId": "c3e91bc9-79ee-462b-bbe4-e54845ddfaec"
      },
      "source": [
        "with tf.name_scope(\"dnn\"):\n",
        "    hidden1 = tf.layers.dense(X, n_hidden1, name=\"hidden1\",\n",
        "                              activation=tf.nn.relu)\n",
        "    hidden2 = tf.layers.dense(hidden1, n_hidden2, name=\"hidden2\",\n",
        "                              activation=tf.nn.relu)\n",
        "    logits = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")\n",
        "    y_proba = tf.nn.softmax(logits)\n",
        "    \n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "    loss_summary = tf.summary.scalar('log_loss', loss)\n",
        "    \n",
        "with tf.name_scope(\"loss\"):\n",
        "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
        "    loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
        "    \n",
        "with tf.name_scope(\"train\"):\n",
        "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "    training_op = optimizer.minimize(loss)\n",
        "    \n",
        "with tf.name_scope(\"eval\"):\n",
        "    correct = tf.nn.in_top_k(logits, y, 1)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "    accuracy_summary = tf.summary.scalar('accuracy', accuracy)\n",
        "    \n",
        "init = tf.global_variables_initializer()\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-64-adb3b44dda9b>:3: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.Dense instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OK0YNiiADo8",
        "outputId": "aabc6e01-194a-4ea3-840e-91cac2ddd7fe"
      },
      "source": [
        "n_epochs = 20\n",
        "n_batches = 50\n",
        "n_epochs = 40\n",
        "batch_size = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    init.run()\n",
        "    for epoch in range(n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_batch = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
        "        acc_valid = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
        "        print(epoch, \"Batch accuracy:\", acc_batch, \"Validation accuracy:\", acc_valid)\n",
        "\n",
        "    save_path = saver.save(sess, \"./my_model_final.ckpt\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 Batch accuracy: 0.9 Validation accuracy: 0.9028\n",
            "1 Batch accuracy: 0.92 Validation accuracy: 0.9252\n",
            "2 Batch accuracy: 0.94 Validation accuracy: 0.9372\n",
            "3 Batch accuracy: 0.9 Validation accuracy: 0.9418\n",
            "4 Batch accuracy: 0.94 Validation accuracy: 0.9472\n",
            "5 Batch accuracy: 0.94 Validation accuracy: 0.951\n",
            "6 Batch accuracy: 1.0 Validation accuracy: 0.9552\n",
            "7 Batch accuracy: 0.94 Validation accuracy: 0.9612\n",
            "8 Batch accuracy: 0.96 Validation accuracy: 0.9618\n",
            "9 Batch accuracy: 0.94 Validation accuracy: 0.965\n",
            "10 Batch accuracy: 0.92 Validation accuracy: 0.9654\n",
            "11 Batch accuracy: 0.98 Validation accuracy: 0.967\n",
            "12 Batch accuracy: 0.98 Validation accuracy: 0.968\n",
            "13 Batch accuracy: 0.98 Validation accuracy: 0.9702\n",
            "14 Batch accuracy: 1.0 Validation accuracy: 0.9696\n",
            "15 Batch accuracy: 0.94 Validation accuracy: 0.9716\n",
            "16 Batch accuracy: 0.98 Validation accuracy: 0.9726\n",
            "17 Batch accuracy: 1.0 Validation accuracy: 0.9728\n",
            "18 Batch accuracy: 0.98 Validation accuracy: 0.9744\n",
            "19 Batch accuracy: 0.98 Validation accuracy: 0.9756\n",
            "20 Batch accuracy: 1.0 Validation accuracy: 0.975\n",
            "21 Batch accuracy: 1.0 Validation accuracy: 0.9732\n",
            "22 Batch accuracy: 0.96 Validation accuracy: 0.975\n",
            "23 Batch accuracy: 0.98 Validation accuracy: 0.9766\n",
            "24 Batch accuracy: 0.98 Validation accuracy: 0.9758\n",
            "25 Batch accuracy: 1.0 Validation accuracy: 0.9762\n",
            "26 Batch accuracy: 0.92 Validation accuracy: 0.977\n",
            "27 Batch accuracy: 1.0 Validation accuracy: 0.9776\n",
            "28 Batch accuracy: 0.94 Validation accuracy: 0.9782\n",
            "29 Batch accuracy: 1.0 Validation accuracy: 0.978\n",
            "30 Batch accuracy: 1.0 Validation accuracy: 0.9776\n",
            "31 Batch accuracy: 1.0 Validation accuracy: 0.9782\n",
            "32 Batch accuracy: 0.96 Validation accuracy: 0.9778\n",
            "33 Batch accuracy: 0.98 Validation accuracy: 0.9784\n",
            "34 Batch accuracy: 0.98 Validation accuracy: 0.978\n",
            "35 Batch accuracy: 1.0 Validation accuracy: 0.9776\n",
            "36 Batch accuracy: 1.0 Validation accuracy: 0.9792\n",
            "37 Batch accuracy: 1.0 Validation accuracy: 0.9784\n",
            "38 Batch accuracy: 0.98 Validation accuracy: 0.9796\n",
            "39 Batch accuracy: 1.0 Validation accuracy: 0.9784\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bap7YofcAFFe"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "def log_dir(prefix=\"\"):\n",
        "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
        "    root_logdir = \"tf_logs\"\n",
        "    if prefix:\n",
        "        prefix += \"-\"\n",
        "    name = prefix + \"run-\" + now\n",
        "    return \"{}/{}/\".format(root_logdir, name)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUt6GX6FAGYt"
      },
      "source": [
        "\n",
        "m, n = X_train.shape\n",
        "logdir = log_dir(\"mnist_dnn\")\n",
        "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V05XC3bIAHDO",
        "outputId": "ef5dab52-efe4-4caa-833c-d730ef655982"
      },
      "source": [
        "n_epochs = 10001\n",
        "batch_size = 50\n",
        "n_batches = int(np.ceil(m / batch_size))\n",
        "\n",
        "checkpoint_path = \"/tmp/my_deep_mnist_model.ckpt\"\n",
        "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
        "final_model_path = \"./my_deep_mnist_model\"\n",
        "\n",
        "best_loss = np.infty\n",
        "epochs_without_progress = 0\n",
        "max_epochs_without_progress = 50\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    if os.path.isfile(checkpoint_epoch_path):\n",
        "        # if the checkpoint file exists, restore the model and load the epoch number\n",
        "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
        "            start_epoch = int(f.read())\n",
        "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
        "        saver.restore(sess, checkpoint_path)\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "        sess.run(init)\n",
        "\n",
        "    for epoch in range(start_epoch, n_epochs):\n",
        "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
        "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
        "        accuracy_val, loss_val, accuracy_summary_str, loss_summary_str = sess.run([accuracy, loss, accuracy_summary, loss_summary], feed_dict={X: X_valid, y: y_valid})\n",
        "        file_writer.add_summary(accuracy_summary_str, epoch)\n",
        "        file_writer.add_summary(loss_summary_str, epoch)\n",
        "        if epoch % 5 == 0:\n",
        "            print(\"Epoch:\", epoch,\n",
        "                  \"\\tValidation accuracy: {:.3f}%\".format(accuracy_val * 100),\n",
        "                  \"\\tLoss: {:.5f}\".format(loss_val))\n",
        "            saver.save(sess, checkpoint_path)\n",
        "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
        "                f.write(b\"%d\" % (epoch + 1))\n",
        "            if loss_val < best_loss:\n",
        "                saver.save(sess, final_model_path)\n",
        "                best_loss = loss_val\n",
        "            else:\n",
        "                epochs_without_progress += 5\n",
        "                if epochs_without_progress > max_epochs_without_progress:\n",
        "                    print(\"Early stopping\")\n",
        "                    break"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 \tValidation accuracy: 90.460% \tLoss: 0.35480\n",
            "Epoch: 5 \tValidation accuracy: 95.140% \tLoss: 0.17555\n",
            "Epoch: 10 \tValidation accuracy: 96.560% \tLoss: 0.12647\n",
            "Epoch: 15 \tValidation accuracy: 97.280% \tLoss: 0.10399\n",
            "Epoch: 20 \tValidation accuracy: 97.480% \tLoss: 0.09201\n",
            "Epoch: 25 \tValidation accuracy: 97.640% \tLoss: 0.08198\n",
            "Epoch: 30 \tValidation accuracy: 97.740% \tLoss: 0.07578\n",
            "Epoch: 35 \tValidation accuracy: 97.760% \tLoss: 0.07291\n",
            "Epoch: 40 \tValidation accuracy: 97.920% \tLoss: 0.06934\n",
            "Epoch: 45 \tValidation accuracy: 98.020% \tLoss: 0.06665\n",
            "Epoch: 50 \tValidation accuracy: 98.000% \tLoss: 0.06685\n",
            "Epoch: 55 \tValidation accuracy: 98.000% \tLoss: 0.06674\n",
            "Epoch: 60 \tValidation accuracy: 98.260% \tLoss: 0.06582\n",
            "Epoch: 65 \tValidation accuracy: 98.100% \tLoss: 0.06831\n",
            "Epoch: 70 \tValidation accuracy: 97.980% \tLoss: 0.06902\n",
            "Epoch: 75 \tValidation accuracy: 98.260% \tLoss: 0.06682\n",
            "Epoch: 80 \tValidation accuracy: 98.100% \tLoss: 0.06931\n",
            "Epoch: 85 \tValidation accuracy: 98.220% \tLoss: 0.06711\n",
            "Epoch: 90 \tValidation accuracy: 98.300% \tLoss: 0.06692\n",
            "Epoch: 95 \tValidation accuracy: 98.280% \tLoss: 0.06770\n",
            "Epoch: 100 \tValidation accuracy: 98.180% \tLoss: 0.06892\n",
            "Epoch: 105 \tValidation accuracy: 98.200% \tLoss: 0.06877\n",
            "Early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAdW1lgIA94s"
      },
      "source": [
        ""
      ],
      "execution_count": 68,
      "outputs": []
    }
  ]
}